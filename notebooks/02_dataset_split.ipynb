{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Splitting\n",
    "\n",
    "This notebook splits the processed dataset into train/val/test sets with the specified distribution:\n",
    "- Train: 1645 images\n",
    "- Val: 151 images\n",
    "- Test: 207 images"
   ],
   "id": "99bbfcaf6635e9a3"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T13:46:33.545239Z",
     "start_time": "2024-11-03T13:46:33.507410Z"
    }
   },
   "source": [
    "import os\n",
    "import shutil\n",
    "import random\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm"
   ],
   "id": "a549e1b51fccb37f",
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T13:46:38.937626Z",
     "start_time": "2024-11-03T13:46:38.922383Z"
    }
   },
   "source": [
    "# Configure paths\n",
    "PROCESSED_PATH = Path('../processed_dataset')\n",
    "OUTPUT_PATH = Path('../fire_detection_dataset')\n",
    "\n",
    "# Create directory structure\n",
    "splits = ['train', 'val', 'test']\n",
    "subdirs = ['images', 'masks', 'labels']\n",
    "\n",
    "for split in splits:\n",
    "    for subdir in subdirs:\n",
    "        (OUTPUT_PATH / split / subdir).mkdir(parents=True, exist_ok=True)"
   ],
   "id": "8f771d0a07a02616",
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T13:48:56.299200Z",
     "start_time": "2024-11-03T13:48:56.287122Z"
    }
   },
   "source": [
    "def split_dataset():\n",
    "    \"\"\"Split the dataset into train/val/test sets.\"\"\"\n",
    "    # Get all image files\n",
    "    image_files = sorted(list((PROCESSED_PATH / 'images').glob('*.jpg')))\n",
    "    random.shuffle(image_files)\n",
    "    \n",
    "    # Calculate split indices\n",
    "    train_size = 1645\n",
    "    val_size = 151\n",
    "    test_size = 207\n",
    "    \n",
    "    # Split the files\n",
    "    train_files = image_files[:train_size]\n",
    "    val_files = image_files[train_size:train_size + val_size]\n",
    "    test_files = image_files[train_size + val_size:train_size + val_size + test_size]\n",
    "    \n",
    "    # Create split mapping\n",
    "    split_mapping = {\n",
    "        'train': train_files,\n",
    "        'val': val_files,\n",
    "        'test': test_files\n",
    "    }\n",
    "    \n",
    "    # Copy files to respective directories\n",
    "    for split, files in split_mapping.items():\n",
    "        print(f\"Processing {split} split...\")\n",
    "        for image_path in tqdm(files):\n",
    "            # Copy image\n",
    "            shutil.copy2(\n",
    "                image_path,\n",
    "                OUTPUT_PATH / split / 'images' / image_path.name\n",
    "            )\n",
    "            \n",
    "            # Copy mask\n",
    "            mask_path = PROCESSED_PATH / 'masks' / f\"{image_path.stem}.png\"\n",
    "            shutil.copy2(\n",
    "                mask_path,\n",
    "                OUTPUT_PATH / split / 'masks' / f\"{image_path.stem}.png\"\n",
    "            )\n",
    "            \n",
    "            # Copy label\n",
    "            label_path = PROCESSED_PATH / 'labels' / f\"{image_path.stem}.txt\"\n",
    "            shutil.copy2(\n",
    "                label_path,\n",
    "                OUTPUT_PATH / split / 'labels' / f\"{image_path.stem}.txt\"\n",
    "            )"
   ],
   "id": "1dacf7caff7c473b",
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T13:48:59.244338Z",
     "start_time": "2024-11-03T13:48:57.082747Z"
    }
   },
   "source": [
    "# Split the dataset\n",
    "split_dataset()"
   ],
   "id": "a50027f5c903e6a2",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing train split...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1645/1645 [00:01<00:00, 936.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing val split...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 151/151 [00:00<00:00, 968.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing test split...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 207/207 [00:00<00:00, 1007.83it/s]\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T13:50:11.708842Z",
     "start_time": "2024-11-03T13:50:11.690189Z"
    }
   },
   "source": [
    "# Create YAML configuration file\n",
    "yaml_content = f\"\"\"path: {str(OUTPUT_PATH.absolute())}  # dataset root dir\n",
    "train: train/images  # train images\n",
    "val: val/images  # val images\n",
    "test: test/images  # test images\n",
    "\n",
    "# Classes\n",
    "names:\n",
    "    0: fire  # fire class\n",
    "\"\"\"\n",
    "\n",
    "with open(OUTPUT_PATH / 'dataset.yaml', 'w') as f:\n",
    "    f.write(yaml_content)"
   ],
   "id": "9b67c009a1f1d8b8",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "62c55a16d461f7c2"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 }
}
