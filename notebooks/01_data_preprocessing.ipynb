{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fire Detection Dataset Preprocessing\n",
    "\n",
    "This notebook handles:\n",
    "1. Resizing images and masks to 512x512\n",
    "2. Converting segmentation masks to YOLO format bounding boxes (handling multiple fires)\n",
    "3. Saving annotations in the required format (including empty annotations)"
   ],
   "id": "a5f7ff3c0e4cd909"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T12:21:31.832040Z",
     "start_time": "2024-11-03T12:21:31.819593Z"
    }
   },
   "source": [
    "import os\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path"
   ],
   "id": "f80bbbf2117f6893",
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T12:16:34.491854Z",
     "start_time": "2024-11-03T12:16:34.476486Z"
    }
   },
   "source": [
    "# Configure paths\n",
    "INPUT_PATH = Path('../dataset')\n",
    "IMAGE_PATH = INPUT_PATH / 'Images'\n",
    "MASK_PATH = INPUT_PATH / 'Masks'\n",
    "OUTPUT_PATH = Path('../processed_dataset')\n",
    "\n",
    "# Create output directories\n",
    "OUTPUT_PATH.mkdir(exist_ok=True)\n",
    "(OUTPUT_PATH / 'images').mkdir(exist_ok=True)\n",
    "(OUTPUT_PATH / 'masks').mkdir(exist_ok=True)\n",
    "(OUTPUT_PATH / 'labels').mkdir(exist_ok=True)"
   ],
   "id": "64b998ad1ac283c5",
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T12:16:38.457879Z",
     "start_time": "2024-11-03T12:16:38.442541Z"
    }
   },
   "source": [
    "def mask_to_bboxes(mask, min_area=10):\n",
    "    \"\"\"Convert binary mask to multiple YOLO format bounding boxes.\n",
    "    \n",
    "    Args:\n",
    "        mask: Binary mask image\n",
    "        min_area: Minimum contour area to consider as a valid fire region\n",
    "        \n",
    "    Returns:\n",
    "        List of bounding boxes in YOLO format [x_center, y_center, width, height]\n",
    "    \"\"\"\n",
    "    # Find contours in the binary mask\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    bboxes = []\n",
    "    image_h, image_w = mask.shape\n",
    "    for contour in contours:\n",
    "        # Filter out small contours\n",
    "        if cv2.contourArea(contour) < min_area:\n",
    "            continue\n",
    "            \n",
    "        x, y, w, h = cv2.boundingRect(contour)\n",
    "        \n",
    "        # Convert to YOLO format (normalized coordinates)\n",
    "        x_center = (x + w/2) / image_w\n",
    "        y_center = (y + h/2) / image_h\n",
    "        width = w / image_w\n",
    "        height = h / image_h\n",
    "        \n",
    "        # Ensure values are within [0, 1]\n",
    "        x_center = max(0, min(1, x_center))\n",
    "        y_center = max(0, min(1, y_center))\n",
    "        width = max(0, min(1, width))\n",
    "        height = max(0, min(1, height))\n",
    "        \n",
    "        bboxes.append([x_center, y_center, width, height])\n",
    "    \n",
    "    return bboxes"
   ],
   "id": "6d3d80d16cfdecae",
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T12:16:40.280542Z",
     "start_time": "2024-11-03T12:16:40.275853Z"
    }
   },
   "source": [
    "def process_image_and_mask(image_path, mask_path, target_size=(512, 512)):\n",
    "    \"\"\"Process single image and mask pair.\"\"\"\n",
    "    # Read image and mask\n",
    "    image = cv2.imread(str(image_path))\n",
    "    if image is None:\n",
    "        raise ValueError(f\"Could not read image: {image_path}\")\n",
    "        \n",
    "    mask = cv2.imread(str(mask_path), cv2.IMREAD_GRAYSCALE)\n",
    "    if mask is None:\n",
    "        raise ValueError(f\"Could not read mask: {mask_path}\")\n",
    "    \n",
    "    # Resize image and mask\n",
    "    image_resized = cv2.resize(image, target_size)\n",
    "    mask_resized = cv2.resize(mask, target_size, interpolation=cv2.INTER_NEAREST)\n",
    "    \n",
    "    # Convert mask to binary\n",
    "    # _, mask_binary = cv2.threshold(mask_resized, 127, 255, cv2.THRESH_BINARY)\n",
    "    \n",
    "    # Get bounding boxes in YOLO format\n",
    "    bboxes = mask_to_bboxes(mask_resized)\n",
    "    \n",
    "    return image_resized, mask_resized, bboxes"
   ],
   "id": "d07af3d016d64346",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T12:16:43.906248Z",
     "start_time": "2024-11-03T12:16:43.817687Z"
    }
   },
   "cell_type": "code",
   "source": [
    "image_path = '../dataset/Images/image_0.jpg'\n",
    "mask_path = '../dataset/Masks/image_0.png'\n",
    "res = process_image_and_mask(image_path, mask_path)"
   ],
   "id": "b7d392b3239decb3",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T12:16:48.167506Z",
     "start_time": "2024-11-03T12:16:48.155563Z"
    }
   },
   "cell_type": "code",
   "source": "res[2]",
   "id": "a5fd0eff2e133877",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.7783203125, 0.2158203125, 0.025390625, 0.033203125],\n",
       " [0.9404296875, 0.201171875, 0.025390625, 0.0234375],\n",
       " [0.5849609375, 0.1982421875, 0.087890625, 0.119140625]]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "a0bc08bbfef51bc5"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T12:16:54.027845Z",
     "start_time": "2024-11-03T12:16:54.011668Z"
    }
   },
   "source": [
    "def process_dataset():\n",
    "    \"\"\"Process all images and masks in the dataset.\"\"\"\n",
    "    image_files = sorted(list(IMAGE_PATH.glob('*.jpg')))\n",
    "    processed_count = 0\n",
    "    error_count = 0\n",
    "    \n",
    "    for image_path in tqdm(image_files):\n",
    "        try:\n",
    "            # Get corresponding mask path\n",
    "            mask_path = MASK_PATH / f\"{image_path.stem}.png\"\n",
    "            \n",
    "            if not mask_path.exists():\n",
    "                print(f\"Warning: No mask found for {image_path}\")\n",
    "                # Create an empty label file\n",
    "                with open(OUTPUT_PATH / 'labels' / f\"{image_path.stem}.txt\", 'w') as f:\n",
    "                    pass\n",
    "                continue\n",
    "            \n",
    "            # Process image and mask\n",
    "            image_resized, mask_resized, bboxes = process_image_and_mask(image_path, mask_path)\n",
    "            \n",
    "            # Save processed files\n",
    "            cv2.imwrite(str(OUTPUT_PATH / 'images' / image_path.name), image_resized)\n",
    "            cv2.imwrite(str(OUTPUT_PATH / 'masks' / mask_path.name), mask_resized)\n",
    "            \n",
    "            # Save YOLO format annotations (even if empty)\n",
    "            with open(OUTPUT_PATH / 'labels' / f\"{image_path.stem}.txt\", 'w') as f:\n",
    "                for bbox in bboxes:\n",
    "                    f.write(f\"0 {' '.join(map(lambda x: f'{x:.6f}', bbox))}\\n\")\n",
    "            \n",
    "            processed_count += 1\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {image_path}: {str(e)}\")\n",
    "            error_count += 1\n",
    "            \n",
    "    print(f\"\\nProcessing complete:\")\n",
    "    print(f\"Successfully processed: {processed_count} images\")\n",
    "    print(f\"Errors encountered: {error_count} images\")"
   ],
   "id": "9b1fd55cf0777511",
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T12:18:55.394075Z",
     "start_time": "2024-11-03T12:17:00.695784Z"
    }
   },
   "source": [
    "# Process the dataset\n",
    "process_dataset()"
   ],
   "id": "c2839ce1a227ed9a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2003/2003 [01:54<00:00, 17.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing complete:\n",
      "Successfully processed: 2003 images\n",
      "Errors encountered: 0 images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T12:21:36.605155Z",
     "start_time": "2024-11-03T12:21:36.588120Z"
    }
   },
   "source": [
    "def verify_processing():\n",
    "    \"\"\"Verify the processed dataset.\"\"\"\n",
    "    print(\"Verifying processed dataset...\")\n",
    "    \n",
    "    # Check directories\n",
    "    for dir_name in ['images', 'masks', 'labels']:\n",
    "        dir_path = OUTPUT_PATH / dir_name\n",
    "        file_count = len(list(dir_path.glob('*')))\n",
    "        print(f\"{dir_name}: {file_count} files\")\n",
    "    \n",
    "    # Verify image sizes\n",
    "    image_files = list((OUTPUT_PATH / 'images').glob('*.jpg'))\n",
    "    if image_files:\n",
    "        sample_image = cv2.imread(str(image_files[0]))\n",
    "        print(f\"\\nImage size: {sample_image.shape}\")\n",
    "        \n",
    "    # Check label format\n",
    "    label_files = list((OUTPUT_PATH / 'labels').glob('*.txt'))\n",
    "    if label_files:\n",
    "        print(\"\\nSample labels:\")\n",
    "        for label_file in random.sample(label_files, min(3, len(label_files))):\n",
    "            with open(label_file, 'r') as f:\n",
    "                content = f.read().strip()\n",
    "                print(f\"{label_file.name}: {content if content else 'empty'}\")"
   ],
   "id": "a811d9bb88c816a",
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-03T12:21:40.989369Z",
     "start_time": "2024-11-03T12:21:40.927276Z"
    }
   },
   "source": [
    "# Verify the processing\n",
    "verify_processing()"
   ],
   "id": "5db6d09670084514",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verifying processed dataset...\n",
      "images: 2003 files\n",
      "masks: 2003 files\n",
      "labels: 2003 files\n",
      "\n",
      "Image size: (512, 512, 3)\n",
      "\n",
      "Sample labels:\n",
      "image_1593.txt: 0 0.542969 0.818359 0.042969 0.085938\n",
      "0 0.333984 0.651367 0.007812 0.013672\n",
      "0 0.317383 0.614258 0.033203 0.150391\n",
      "0 0.006836 0.144531 0.013672 0.042969\n",
      "image_381.txt: 0 0.541992 0.084961 0.013672 0.021484\n",
      "0 0.569336 0.065430 0.013672 0.037109\n",
      "0 0.566406 0.031250 0.011719 0.019531\n",
      "0 0.554688 0.025391 0.011719 0.015625\n",
      "image_1859.txt: 0 0.073242 0.994141 0.009766 0.011719\n",
      "0 0.111328 0.969727 0.015625 0.025391\n",
      "0 0.502930 0.887695 0.060547 0.119141\n",
      "0 0.170898 0.441406 0.013672 0.035156\n",
      "0 0.448242 0.353516 0.013672 0.042969\n",
      "0 0.279297 0.220703 0.007812 0.023438\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c1e7deeef9ff49a3"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 }
}
