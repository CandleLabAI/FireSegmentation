{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-24T07:11:18.362289Z",
     "start_time": "2024-11-24T07:11:15.927524Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from skimage.color import rgb2lab\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T07:11:21.829689Z",
     "start_time": "2024-11-24T07:11:21.815324Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def read_bounding_boxes(label_path):\n",
    "    \"\"\"Read YOLO format bounding boxes and convert to pixel coordinates.\"\"\"\n",
    "    boxes = []\n",
    "    if label_path.exists():\n",
    "        with open(label_path, 'r') as f:\n",
    "            for line in f:\n",
    "                if line.strip():\n",
    "                    # Parse YOLO format: class x_center y_center width height\n",
    "                    _, x_center, y_center, width, height = map(float, line.strip().split())\n",
    "                    \n",
    "                    # Convert to pixel coordinates (assuming 512x512 images)\n",
    "                    img_width = img_height = 512\n",
    "                    x1 = int((x_center - width/2) * img_width)\n",
    "                    y1 = int((y_center - height/2) * img_height)\n",
    "                    x2 = int((x_center + width/2) * img_width)\n",
    "                    y2 = int((y_center + height/2) * img_height)\n",
    "                    \n",
    "                    # Ensure coordinates are within image bounds\n",
    "                    x1 = max(0, min(img_width, x1))\n",
    "                    y1 = max(0, min(img_height, y1))\n",
    "                    x2 = max(0, min(img_width, x2))\n",
    "                    y2 = max(0, min(img_height, y2))\n",
    "                    \n",
    "                    boxes.append([x1, y1, x2, y2])\n",
    "    return boxes"
   ],
   "id": "5987b862ea1a7314",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T07:11:38.059119Z",
     "start_time": "2024-11-24T07:11:38.044897Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_cielab_mask(lab_image, hue_lower=-14.98, hue_upper=96.22, chroma_threshold=6.11):\n",
    "    \"\"\"Create binary mask using CIELAB color space.\"\"\"\n",
    "    # Extract a* and b* components\n",
    "    a = lab_image[:, :, 1]\n",
    "    b = lab_image[:, :, 2]\n",
    "    \n",
    "    # Calculate hue in degrees\n",
    "    hue = np.degrees(np.arctan2(b, a))\n",
    "    \n",
    "    # Ensure hue is in range [-180, 180]\n",
    "    hue = np.where(hue < -180, hue + 360, hue)\n",
    "    hue = np.where(hue > 180, hue - 360, hue)\n",
    "    \n",
    "    # Calculate chroma\n",
    "    chroma = np.sqrt(a**2 + b**2)\n",
    "    \n",
    "    # Create binary mask\n",
    "    mask = np.zeros_like(hue, dtype=np.uint8)\n",
    "    \n",
    "    # Apply conditions\n",
    "    fire_pixels = (hue >= hue_lower) & (hue <= hue_upper) & (chroma >= chroma_threshold)\n",
    "    mask[fire_pixels] = 255\n",
    "    \n",
    "    return mask"
   ],
   "id": "c5c7cc74534c6fb0",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T07:12:02.542500Z",
     "start_time": "2024-11-24T07:12:02.531296Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def create_multichannel_image(image_path, label_path):\n",
    "    \"\"\"Create 8-channel image from RGB image and bounding boxes.\"\"\"\n",
    "    # Read image and convert to RGB\n",
    "    image = cv2.imread(str(image_path))\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Read bounding boxes\n",
    "    boxes = read_bounding_boxes(label_path)\n",
    "    \n",
    "    # Create masks for bounding boxes\n",
    "    box_mask = np.zeros(image.shape[:2], dtype=np.uint8)\n",
    "    for box in boxes:\n",
    "        x1, y1, x2, y2 = box\n",
    "        box_mask[y1:y2, x1:x2] = 255\n",
    "    \n",
    "    # Convert to CIELAB\n",
    "    lab_image = rgb2lab(image)\n",
    "    \n",
    "    # Create CIELAB mask only within bounding boxes\n",
    "    cielab_mask = np.zeros_like(box_mask)\n",
    "    for box in boxes:\n",
    "        x1, y1, x2, y2 = box\n",
    "        box_lab = lab_image[y1:y2, x1:x2]\n",
    "        box_cielab_mask = create_cielab_mask(box_lab)\n",
    "        cielab_mask[y1:y2, x1:x2] = box_cielab_mask\n",
    "    \n",
    "    # Create first 4-channel image (RGB + CIELAB aux)\n",
    "    first_4ch = np.dstack((image, cielab_mask))\n",
    "    \n",
    "    # Create second RGB image (only within boxes)\n",
    "    masked_image = np.zeros_like(image)\n",
    "    for box in boxes:\n",
    "        x1, y1, x2, y2 = box\n",
    "        masked_image[y1:y2, x1:x2] = image[y1:y2, x1:x2]\n",
    "    \n",
    "    # Create second 4-channel image\n",
    "    second_4ch = np.dstack((masked_image, cielab_mask))\n",
    "    \n",
    "    # Combine into 8-channel image\n",
    "    multichannel = np.dstack((first_4ch, second_4ch))\n",
    "    \n",
    "    return multichannel"
   ],
   "id": "5100ad200d2fa9b",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T07:15:34.806746Z",
     "start_time": "2024-11-24T07:15:34.799496Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def process_dataset(dataset_path='../fire_detection_dataset'):\n",
    "    \"\"\"Process all images in the dataset.\"\"\"\n",
    "    dataset_path = Path(dataset_path)\n",
    "    total_processed = 0\n",
    "    total_errors = 0\n",
    "    \n",
    "    for split in ['train', 'val', 'test']:\n",
    "        print(f\"\\nProcessing {split} split...\")\n",
    "        \n",
    "        # Create output directory if it doesn't exist\n",
    "        (dataset_path / split / 'multichannel').mkdir(exist_ok=True)\n",
    "        \n",
    "        # Get all images in the split\n",
    "        image_paths = list((dataset_path / split / 'images').glob('*.jpg'))\n",
    "        \n",
    "        for image_path in tqdm(image_paths):\n",
    "            try:\n",
    "                # Get corresponding label path\n",
    "                label_path = dataset_path / split / 'labels' / f\"{image_path.stem}.txt\"\n",
    "                \n",
    "                # Create multichannel image\n",
    "                multichannel = create_multichannel_image(image_path, label_path)\n",
    "                \n",
    "                # Save as numpy array\n",
    "                output_path = dataset_path / split / 'multichannel' / f\"{image_path.stem}.npy\"\n",
    "                np.save(str(output_path), multichannel)\n",
    "                \n",
    "                total_processed += 1\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {image_path}: {str(e)}\")\n",
    "                total_errors += 1\n",
    "                continue"
   ],
   "id": "f5d5aa75791085c",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T07:16:43.758991Z",
     "start_time": "2024-11-24T07:15:35.484463Z"
    }
   },
   "cell_type": "code",
   "source": "process_dataset()",
   "id": "e6e65b9d2bca6bfd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing train split...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1645/1645 [00:56<00:00, 29.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing val split...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 151/151 [00:04<00:00, 31.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing test split...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 207/207 [00:06<00:00, 30.01it/s]\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def visualize_channels(multichannel):\n",
    "    \"\"\"Visualize all channels of a multichannel image.\"\"\"\n",
    "    # Create figure\n",
    "    fig, axes = plt.subplots(2, 4, figsize=(20, 10))\n",
    "    \n",
    "    # Channel names\n",
    "    channel_names = [\n",
    "        'RGB-R (Full)', 'RGB-G (Full)', 'RGB-B (Full)', 'CIELAB Aux',\n",
    "        'RGB-R (Boxed)', 'RGB-G (Boxed)', 'RGB-B (Boxed)', 'CIELAB Aux'\n",
    "    ]\n",
    "    \n",
    "    # Plot each channel\n",
    "    for i in range(8):\n",
    "        row = i // 4\n",
    "        col = i % 4\n",
    "        \n",
    "        axes[row, col].imshow(multichannel[:, :, i], cmap='gray')\n",
    "        axes[row, col].set_title(channel_names[i])\n",
    "        axes[row, col].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ],
   "id": "2f8224ea7fd101a5"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
